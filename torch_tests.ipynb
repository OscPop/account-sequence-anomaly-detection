{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set pandas options\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# Read data\n",
    "df=pd.read_csv(Path('data/book.txt'), \n",
    "    sep='|', \n",
    "    header=0,\n",
    "    encoding='utf-8', \n",
    "    low_memory=False, \n",
    "    decimal=',', \n",
    "    parse_dates=['voucher_date', 'last_update'])\n",
    "\n",
    "df = df[df['voucher_type'] == 'VB']\n",
    "df=df.sort_values(by=['voucher_no','sequence_no'])\n",
    "\n",
    "# set account dtype to int\n",
    "df['account'] = df['account'].astype(int)\n",
    "\n",
    "# collapse by voucher_no and list account_no\n",
    "df = df.groupby('voucher_no').agg(\n",
    "    {'account':list}\n",
    ")\n",
    "\n",
    "# Replace with your actual data\n",
    "sequences = df.account.tolist()\n",
    "\n",
    "# Flatten the sequences and create a set of unique account numbers\n",
    "flat_sequences = [account for seq in sequences for account in seq]\n",
    "unique_accounts = set(flat_sequences)\n",
    "\n",
    "# Encode the account numbers as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(list(unique_accounts))\n",
    "\n",
    "# save encoder\n",
    "import pickle\n",
    "with open('encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.intersect1d(np.array(list(unique_accounts)), encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv(Path('data/book.txt'), \n",
    "    sep='|', \n",
    "    header=0,\n",
    "    encoding='utf-8', \n",
    "    low_memory=False, \n",
    "    decimal=',', \n",
    "    parse_dates=['voucher_date', 'last_update'])\n",
    "\n",
    "df2.account.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.loc[df2.voucher_type == \"VB\"]\n",
    "df3.account.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SeriesGroupBy' object has no attribute 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df3\u001b[39m.\u001b[39;49mgroupby(\u001b[39m\"\u001b[39;49m\u001b[39mvoucher_no\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49maccount\u001b[39m.\u001b[39;49mlist()\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:987\u001b[0m, in \u001b[0;36mGroupBy.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj:\n\u001b[0;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[attr]\n\u001b[1;32m--> 987\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m    988\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    989\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SeriesGroupBy' object has no attribute 'list'"
     ]
    }
   ],
   "source": [
    "df3.groupby(\"voucher_no\").account.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set pandas options\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# Read data\n",
    "df=pd.read_csv(Path('data/book.txt'), \n",
    "    sep='|', \n",
    "    header=0,\n",
    "    encoding='utf-8', \n",
    "    low_memory=False, \n",
    "    decimal=',', \n",
    "    parse_dates=['voucher_date', 'last_update'])\n",
    "\n",
    "df = df[df['voucher_type'] == 'VB']\n",
    "df=df.sort_values(by=['voucher_no','sequence_no'])\n",
    "\n",
    "# set account dtype to int\n",
    "df['account'] = df['account'].astype(int)\n",
    "\n",
    "# collapse by voucher_no and list account_no\n",
    "df = df.groupby('voucher_no').agg(\n",
    "    {'account':list}\n",
    ")\n",
    "\n",
    "# Replace with your actual data\n",
    "sequences = df.account.tolist()\n",
    "\n",
    "# Flatten the sequences and create a set of unique account numbers\n",
    "flat_sequences = [account for seq in sequences for account in seq]\n",
    "unique_accounts = set(flat_sequences)\n",
    "\n",
    "# Encode the account numbers as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(list(unique_accounts))\n",
    "\n",
    "# save encoder\n",
    "import pickle\n",
    "with open('encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "\n",
    "# Encode the sequences and pad them with -1 to a fixed length: maximum sequence length\n",
    "max_seq_length = max([len(seq) for seq in sequences])\n",
    "encoded_sequences = [encoder.transform(seq).tolist() for seq in sequences]\n",
    "padded_sequences = [seq + [0] * (max_seq_length - len(seq)) for seq in encoded_sequences]\n",
    "#padded_sequences = [seq + [0] * (max_seq_length - len(seq)) for seq in sequences]\n",
    "\n",
    "with open('encoded_sequences.pkl', 'wb') as f:\n",
    "    pickle.dump(encoded_sequences, f)\n",
    "\n",
    "# Create input-output pairs for training\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Create input-output pairs for training\n",
    "data = []\n",
    "for seq in padded_sequences:\n",
    "    for i in range(1, len(seq)):\n",
    "        data.append((seq[:i], seq[i]))\n",
    "\n",
    "with open('data.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "class AccountSequenceDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.data[idx]\n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    targets_1d = [torch.tensor([t], dtype=torch.long) for t in targets]\n",
    "    targets_padded = pad_sequence(targets_1d, batch_first=True, padding_value=0)\n",
    "    return inputs_padded, targets_padded\n",
    "\n",
    "\n",
    "dataset = AccountSequenceDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_layers):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_layers)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def generate_mask(self, size):\n",
    "        mask = torch.tril(torch.ones(size, size) == 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x)\n",
    "        tgt_mask = self.generate_mask(x.size(1)).to(device)\n",
    "\n",
    "        src_key_padding_mask = (x == 0)\n",
    "        tgt_key_padding_mask = (x == 0)\n",
    "        output = self.transformer(embed, embed, tgt_mask=tgt_mask, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "        logits = self.fc(output)\n",
    "        return logits\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Model and training parameters\n",
    "vocab_size = len(unique_accounts) + 1\n",
    "d_model = 128\n",
    "nhead = 4\n",
    "num_layers = 2\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "\n",
    "model = TransformerModel(vocab_size, d_model, nhead, num_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "max_val = 0\n",
    "min_val = 101\n",
    "for seq in encoded_sequences:\n",
    "    max_val = max(max_val, max(seq))\n",
    "    min_val = min(min_val, min(seq))\n",
    "\n",
    "print(max_val)\n",
    "print(min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique = pd.DataFrame(np.array(list(unique_accounts)), columns=[\"acc\"])\n",
    "df_unique.acc.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18]), tensor(18))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [6] at entry 0 and [12] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[189], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(batch\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:264\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    204\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;49;00m samples \u001b[39min\u001b[39;49;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[0;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [6] at entry 0 and [12] at entry 1"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch index:  0\n",
      "Batch x size:  torch.Size([15])\n",
      "Batch x label:  tensor([64,  1,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "Batch y size:  torch.Size([1])\n",
      "Batch y label:  tensor([0])\n",
      "Shape x: torch.Size([32, 15])\n",
      "Shape y: torch.Size([32, 1])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "expecting key_padding_mask shape of (15, 32), but got torch.Size([32, 15])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape y: \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 16\u001b[0m logits \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m     17\u001b[0m logits_reshaped \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, logits\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     18\u001b[0m y_reshaped \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[61], line 117\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    115\u001b[0m src_key_padding_mask \u001b[39m=\u001b[39m (x \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m    116\u001b[0m tgt_key_padding_mask \u001b[39m=\u001b[39m (x \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m--> 117\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(embed, embed, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask, tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask)\n\u001b[0;32m    118\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(output)\n\u001b[0;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m logits\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:145\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m src\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model \u001b[39mor\u001b[39;00m tgt\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model:\n\u001b[0;32m    143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 145\u001b[0m memory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(src, mask\u001b[39m=\u001b[39;49msrc_mask, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask)\n\u001b[0;32m    146\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(tgt, memory, tgt_mask\u001b[39m=\u001b[39mtgt_mask, memory_mask\u001b[39m=\u001b[39mmemory_mask,\n\u001b[0;32m    147\u001b[0m                       tgt_key_padding_mask\u001b[39m=\u001b[39mtgt_key_padding_mask,\n\u001b[0;32m    148\u001b[0m                       memory_key_padding_mask\u001b[39m=\u001b[39mmemory_key_padding_mask)\n\u001b[0;32m    149\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:306\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    303\u001b[0m is_causal \u001b[39m=\u001b[39m make_causal\n\u001b[0;32m    305\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 306\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[0;32m    308\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    309\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:573\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    571\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[0;32m    572\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 573\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask))\n\u001b[0;32m    574\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[0;32m    576\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:581\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[0;32m    580\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 581\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[0;32m    582\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m    583\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m    584\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    585\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1189\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1175\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1176\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[0;32m   1177\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1186\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1187\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[0;32m   1188\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1189\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[0;32m   1190\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[0;32m   1191\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[0;32m   1192\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[0;32m   1193\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m   1194\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[0;32m   1195\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m   1196\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[0;32m   1197\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m   1198\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[0;32m   1199\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[0;32m   1200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[0;32m   1201\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mc:\\Users\\OscarLarsen\\miniconda3\\envs\\fail_env\\Lib\\site-packages\\torch\\nn\\functional.py:5276\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5274\u001b[0m \u001b[39m# merge key padding and attention masks\u001b[39;00m\n\u001b[0;32m   5275\u001b[0m \u001b[39mif\u001b[39;00m key_padding_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 5276\u001b[0m     \u001b[39massert\u001b[39;00m key_padding_mask\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (bsz, src_len), \\\n\u001b[0;32m   5277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpecting key_padding_mask shape of \u001b[39m\u001b[39m{\u001b[39;00m(bsz,\u001b[39m \u001b[39msrc_len)\u001b[39m}\u001b[39;00m\u001b[39m, but got \u001b[39m\u001b[39m{\u001b[39;00mkey_padding_mask\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   5278\u001b[0m     key_padding_mask \u001b[39m=\u001b[39m key_padding_mask\u001b[39m.\u001b[39mview(bsz, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, src_len)\u001b[39m.\u001b[39m   \\\n\u001b[0;32m   5279\u001b[0m         expand(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, num_heads, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreshape(bsz \u001b[39m*\u001b[39m num_heads, \u001b[39m1\u001b[39m, src_len)\n\u001b[0;32m   5280\u001b[0m     \u001b[39mif\u001b[39;00m attn_mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mAssertionError\u001b[0m: expecting key_padding_mask shape of (15, 32), but got torch.Size([32, 15])"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (x, y) in enumerate(dataloader):\n",
    "        print('Batch index: ', batch_idx)\n",
    "        print('Batch x size: ', x[0].size())\n",
    "        print('Batch x label: ', x[1])\n",
    "        print('Batch y size: ', y[0].size())\n",
    "        print('Batch y label: ', y[1])\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        print(f\"Shape x: {x.shape}\")\n",
    "        print(f\"Shape y: {y.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        logits_reshaped = logits.view(-1, logits.size(-1))\n",
    "        y_reshaped = y.view(-1)\n",
    "        valid_indices = y_reshaped != 0\n",
    "        logits_masked = torch.masked_select(logits_reshaped, valid_indices.unsqueeze(1)).view(-1, logits.size(-1))\n",
    "        y_masked = torch.masked_select(y_reshaped, valid_indices)\n",
    "        loss = criterion(logits_masked, y_masked)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# save the model\n",
    "torch.save(model.state_dict(), 'models/LSTM_model.pt')\n",
    "\n",
    "# apply outlier detection\n",
    "def calculate_reconstruction_loss(model, dataloader, device):\n",
    "    losses = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "            losses.append(loss.item())\n",
    "    return losses\n",
    "\n",
    "reconstruction_losses = calculate_reconstruction_loss(model, dataloader, device)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "mean_loss = np.mean(reconstruction_losses)\n",
    "std_loss = np.std(reconstruction_losses)\n",
    "threshold = mean_loss + 2 * std_loss\n",
    "\n",
    "outliers = [seq for seq, loss in zip(sequences, reconstruction_losses) if loss > threshold]\n",
    "\n",
    "print(f\"Number of outliers: {len(outliers)}\")\n",
    "\n",
    "# save outliers\n",
    "with open('Result/outliers.pkl', 'wb') as f:\n",
    "    pickle.dump(outliers, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(97)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset[45][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 32])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
